{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Optimizers and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers and Data Shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Optimizers.jpg\">\n",
    "<img src = \"Optimizers1.jpg\">\n",
    "<img src = \"Optimizers2.jpg\">\n",
    "<img src = \"Optimizers3.jpg\">\n",
    "<img src = \"Optimizers4.jpg\">\n",
    "<img src = \"Optimizers5.jpg\">\n",
    "<img src = \"Optimizers6.jpg\">\n",
    "<img src = \"Optimizers7.jpg\">\n",
    "<img src = \"Optimizers8.jpg\">\n",
    "<img src = \"Optimizers9.jpg\">\n",
    "<img src = \"Optimizers10.jpg\">\n",
    "<img src = \"Optimizers11.jpg\">\n",
    "<img src = \"Optimizers12.jpg\">\n",
    "<img src = \"Optimizers13.jpg\">\n",
    "<img src = \"Optimizers14.jpg\">\n",
    "<img src = \"Optimizers15.jpg\">\n",
    "<img src = \"Optimizers16.jpg\">\n",
    "<img src = \"Optimizers17.jpg\">\n",
    "<img src = \"Optimizers18.jpg\">\n",
    "<img src = \"Optimizers19.jpg\">\n",
    "<img src = \"Optimizers20.jpg\">\n",
    "<img src = \"Optimizers21.jpg\">\n",
    "<img src = \"Optimizers22.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>190</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.549</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.654</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>78</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.495</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.805</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.516</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "541               3                     128              72              25   \n",
       "117               5                      78              48               0   \n",
       "169               3                     111              90              12   \n",
       "221               2                     158              90               0   \n",
       "424               8                     151              78              32   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "541      190  32.4              0.549   27             1  \n",
       "117        0  33.7              0.654   25             0  \n",
       "169       78  28.4              0.495   29             0  \n",
       "221        0  31.6              0.805   66             1  \n",
       "424      210  42.9              0.516   36             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.816\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 0.5121 - accuracy: 0.7465 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7483 - val_loss: 0.5172 - val_accuracy: 0.7708\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7483 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7483 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7483 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7500 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7500 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7500 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7500 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7500 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7500 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7500 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7500 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7500 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7500 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7517 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7517 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7517 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7517 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7517 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7517 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7517 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7535 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7535 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7535 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7535 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7552 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7535 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7535 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5064 - accuracy: 0.7535 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7535 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7552 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7552 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7552 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7552 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7552 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7552 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7552 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7552 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7552 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7552 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7552 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7552 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7552 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7552 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7552 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7552 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7552 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7552 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7535 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7552 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7569 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7552 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7552 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7552 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7552 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7552 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7552 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7552 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7552 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7552 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7569 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7552 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7569 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7569 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7552 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7569 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7569 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7552 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7552 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7552 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7552 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7552 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7552 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7552 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.7552 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7552 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7552 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7552 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7552 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7552 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7552 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7552 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7552 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7569 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7587 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7587 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7587 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7604 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7587 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7604 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7604 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7604 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7604 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7604 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7587 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7604 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7604 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7587 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7569 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7587 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7587 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7587 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7587 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7604 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7604 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7604 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7604 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7604 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7622 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7622 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7622 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7622 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7622 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7622 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7622 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7622 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7622 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7622 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7622 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7622 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7622 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7604 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7622 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7604 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7622 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7622 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7604 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7639 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7639 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7622 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7622 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7622 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7622 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7639 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7622 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7622 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7622 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7622 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7622 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7622 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7639 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7622 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7622 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7622 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7622 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7622 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7622 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7622 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7622 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7622 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7622 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7622 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7622 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7622 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7622 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7622 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7622 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7622 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7622 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7622 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7622 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7622 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7622 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7622 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7622 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7622 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7622 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7622 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7622 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7622 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7622 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7622 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7622 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7622 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7622 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7622 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7622 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7622 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7622 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7622 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7622 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7622 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7622 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7622 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7622 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7622 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7622 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7622 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7622 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7622 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7622 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7622 - val_loss: 0.4945 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "predict_x = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = np.argmax(predict_x,axis=1)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39382648],\n",
       "       [0.6737734 ],\n",
       "       [0.34199223],\n",
       "       [0.32650706],\n",
       "       [0.21179733],\n",
       "       [0.49144122],\n",
       "       [0.09918064],\n",
       "       [0.31075722],\n",
       "       [0.76884234],\n",
       "       [0.24947184]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.641\n",
      "roc-auc is 0.823\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8H0lEQVR4nO3dd5hU5fn/8c9NV4RFiihFUBeCiGYxIMagbuwGvxo1+hNUMNGYolFBqgKCCqgoqIkkro2gWXsJRqzRFcUCiKs0QZoUAWlLh23P748zkGXdMrs7M8+U9+u6uJxyduYzz4xzz33Oc84x55wAAED8qOU7AAAAOBDFGQCAOENxBgAgzlCcAQCIMxRnAADiDMUZAIA4Q3FGyjGzg8zsdTPbamYv+s6TqsxsspndHbp8qpktCvPvrjGzj6Obzq/KXqOZ5ZjZdbHMhNiiOCc5M1thZrvNbIeZrQt9IR5SaplTzOx9M9seKlivm1nnUss0NrMHzWxl6LGWhq43L+d5zcxuMrN5ZrbTzFab2Ytmdnw0X2+YfiOppaRmzrnLavpgZpZpZs7MJpW6/WMzuyZ0+ZrQMoNLLbPazDJrmiGMjCU/B+tLfg5KftGXeC2vlvr7n4Zuzyl1u5nZMjNbUJN8zrmPnHM/qcljhCMVCjuSA8U5Nfyfc+4QSRmSukoatu8OM/u5pHck/VtSK0lHSfpK0gwzOzq0TD1J/5V0nKTzJDWW9HNJmySdVM5zPiTpZkk3SWoqqaOk1yT1qmp4M6tT1b+pRDtJi51zhRHMslPS1WbWvoI/3yxpsJk1qurzRsi+z8GJkrpJGl7Ochsk/dzMmpW4rZ+kxWUse5qkwyQdbWbdIxk2mUXhM40kQ3FOIc65dZLeVlCk97lP0hTn3EPOue3Ouc3OueGSPpM0KrRMX0lHSrrYObfAOVfsnPvBOXeXc25a6ecxsw6SbpDU2zn3vnNur3Nul3PuX865e0LLHLBarnRHE+rSbjCzbyV9a2Z/N7P7Sz3Pv81sQOhyKzN72cw2mNlyM7uprDEws9GSRkr6f6Eu8lozq2Vmw83sOzP7wcymmFlaaPn2oSzXmtlKSe+XM7x5kiZLuqOc+yVpoaRPJQ2oYJmSWdNCWTaEsg03s1qh+64Jdeb3m9mW0Gs+P5zHdc6tkfSmpC7lLJKv4IfUFaHnqi3p/0n6VxnL9lPww25a6HJFr6ermc0JraF5XlKDEvdlmtnqEteHhtbObDezBWZ28Y8fzv4WWtPzjZmdWeKONDN7wszWmtkaM7vbzGqb2bGS/qHgh8cOM8sLLV8/NI4rQ2sV/mFmB4Xua25m/zGzPDPbbGYf7XsPynh9zoK1RcvMbKOZjS/1fs0ws4lmtknSqIre38peYxnP/TszWxj6LLxtZu1K5fqzmX0bGs+7zOwYM/vEzLaZ2QsW/ABHHKE4pxAzayPpfElLQtcPlnSKpLK2u74g6ezQ5bMkveWc2xHmU50pabVzbmbNEuvXknpI6izpWQUF1STJzA6VdI6k50JfaK8r6Phbh57/FjM7t/QDOufukDRW0vPOuUOcc09Iuib075eSjpZ0iKS/lfrT0yUdK+lHj1nCGEmXmllFq2dHhLI1rWCZff4qKS2U6XQFP5J+W+L+HpIWSWqu4EfWE/vGpyJm1lbSryR9WcFiU0LPJwWveZ6k70s9zsEKNhH8K/TvivK+5EO3vybpaQVrUl6UdGkFz79U0qkKXv9oSc+Y2REl7u8RWqa5gh9Er5QY08mSCiWlK1hTdI6k65xzCyX9UdKnofe+SWj5exSs2ckI/U1rBT/gJOlWSasltVCwKeQ2SRUd8/hiBWslTpR0kaTflcq8LPQ4YxTe+1vea9zPzC4K5boklPMjBf+/lHSupJ9JOlnSYElZkq6S1FbBj7TeFbwmeEBxTg2vmdl2Sask/aD/dXdNFXwG1pbxN2sVfClIUrNylilPVZcvz7hQJ79bwReOU/CFLQVF4VPn3PeSuktq4Zy70zmX75xbJukxhTq/MFwpaYJzblnoB8gwBYWm5KrHUc65naEsZQqtmfiHpDsrWCZX0ruShlQUKNStXiFpWGiNxgpJD0i6usRi3znnHnPOFUn6p6QjFHzxl+e1ULf4saQPFfxIKS/nJ5Kahn5o9FVQrEu7RNJeBZtF3pBUV+Vvtjg5dP+DzrkC59xLkmZV8PwvOue+D62leV7StzpwE8oPJR7reQU/UnqZWUsFPzxuCb1fP0iaqHI+C6EfM9dL6h/6rG1XMC77li9QMK7tQs/1kav4hAT3hh5npaQHdWDR+94599fQ5pR8Vf7+lvkay3jOPyr4f2Vh6LHHSsoo2T1Lus85t805N1/BD613Qp/3rQrWonSt4DXBA4pzavi1c66RpExJnfS/ortFUrGCL5/SjpC0MXR5UznLlKeqy5dn1b4LoS/E5/S/L7s++t9q1naSWoVWPeaFCtBtqrhQldRK0nclrn8nqU6pv1+l8Nwr6Vwz+2kFy4yU9KdQISlPcwXFrHSu1iWur9t3wTm3K3TxgMl+pfzaOdfEOdfOOffnin5ohDwt6UYFaxReLeP+fpJecM4VOuf2SHpZ5a/abiVpTanC9l05y8rM+ppZbon3s4v+97lVOY/VSsFnoa6ktSX+9lEF28XL0kLSwZK+KLH8W6HbJWm8gjVN74RWVw8tL3NIyc/Jvkxl3RfO+1veayytnaSHSuTfLMlKPdb6Epd3l3G9os8NPKA4pxDn3IcKVvndH7q+U8E20LJmLF+uYBKYJL2noOA0DPOp/iupjZl1q2CZnQq+FPc5vKzIpa4/K+k3oY6gh4JiIAVfestDhWffv0bOuV+Fmfd7BV9w+xypYLVoyS+wsE7f5pzbpKBjuquCZb6R9Iqk2yt4qI0KurbSudaEkyNCnpb0Z0nTShR/Sfs3kZwh6SoL9gJYp2Btxq+s7Bn8ayW1LrXa/ciynjT0/j6m4IdBs9Dq53kKCs4+ZT3W9wo+C3slNS/xWWjsnDsutFzp93GjguJ0XInl00IT5xTqam91zh0t6UJJAyra9qtgNXHpTPuUfO5w3t/yXmNpqyT9odTn/6DQ2g8kKIpz6nlQ0tklOruhkvqFJrI0MrNDLdj39OcKtvVJwZf0Kkkvm1knCyZQNTOz28zsRwXQOfetpEmSnrVgok89M2tgZleU6DxyJV1iZgebWbqkaysL7pz7UsGX2uOS3nbO5YXumilpu5kNsWAf5tpm1sXCnz38rKT+ZnaUBbsX7dsmXeXZ3CETFGzLP7aCZUYr2L7YpKw7Q6uqX5A0JvS+tFMwkeyZamaqMufccgXbQsv6EXG1gtnbP1GwrTZDwXbb1Sp7++WnCn7w3GRmdc3sEpU/07+hgkK2QZLM7Lf68eS1w0o81mUKxnqac26tgtXsD1iw+1+t0OSn00N/t17BD8d6oddYrOCHwEQzOyz0fK33zVcwswvMLD1UJLdKKlKwtqk8g0L/D7VVsLfC82UtFOb7W+ZrLOPh/iFpmJkdF8qcFloeCYzinGKccxsUbD8cGbr+sYLJIpco6G6+U7D9qWeoyMo5t1fBpLBvFGwv3aagIDaX9Hk5T3WTgklVjyiYybxUwWSZ10P3T1Sw3W29gu2lZc0ELkt2KEt2iddUJOkCBQViuf5XwNPCfMwnFfwAmR76+z2S/hLm3/6Ic26bggla5U76ChW+pxUUovL8RcEahmUKthNnh7LGjHPu49B2/dL6SZrknFtX8p+CQvGjVdvOuXwFn7FrFKx2/X8K1h6U9ZwLFGx//VTB5+N4STNKLfa5pA4K3usxkn4TWmshBdvI60laoGDTzUv632aW9yXNl7TOzPZtthmiYNX1Z2a2TcGaon2T+jqEru8I5ZnknPugrNwh/5b0hYIfn29IeqKCZSt7fyt6jfs5515VsDnluVD+eQomfiKBWcVzGwAA4TAzJ6mDc26J7yxIfHTOAADEGYozAABxhtXaAADEGTpnAADiDMUZAIA4U+mZUczsSQW7qfzgnPvRgfJD+/89pOCQebskXeOcm1PZ4zZv3ty1b99+//WdO3eqYcNwj3GBqmJ8o4vxjR7GNroY3+gpPbZffPHFRudciwr+ZL9wTls2WcH+qmUdW1cK9qfrEPrXQ9LfQ/+tUPv27TV79uz913NycpSZmRlGHFQH4xtdjG/0MLbRxfhGT+mxNbNyD1lbWqWrtZ1z0xUcNKA8Fyk45aBzzn0mqUmps8cAAIAqiMQJv1vrwAO6rw7dFomzEgEAEBeysrKUnZ1d+YIhzZs3r/ZaiUgU57CZ2fUKTs+mli1bKicnZ/99O3bsOOA6IovxjS7GN3oY2+hifMM3adIkLVmyROnp6RUu55zT+vXrlZGRUe2xjURxXqMDz8TSRuWcOcc5l6XgJN/q1q2bK/mLgu0e0cX4RhfjGz2MbXQxvuFr0qSJunXrVmHBLS4u1sKFC1WvXj2tWbOm2mMbiV2ppkrqa4GTJW0NnRkGAICU4ZzTsGHD5JxThw4davRY4exK9aykTEnNzWy1pDsUnCRczrl/KDiF2a8UnNVll4LT4AEAkDIKCgo0Y8YMDR06VIceemiNH6/S4uycK+vcrCXvd5JuqHESAAAS1F133aW+fftGpDBLMZ4QBgBITlWdyZyIcnNzlZGRccBte/fu1csvv6w77rhDtWvXjthzcfhOAECNZWdnKzc313eMqMrIyFCfPn0OuG3SpEnq2bNnRAuzROcMAIiQmuw6lGh27typRx99VAMGDIjK49M5AwBQRa+99tqPuuhIojgDABCmrVu3asiQIerTp48OP/zwqD0PxRkAgDDk5+dr5syZGjJkiIITMkYPxRkAgEps3LhR/fv31+mnn66mTZtG/fmYEAYAMRZPux3l5eWpSZMmNX6csnYzShabNm3Sd999p3HjxqlevXoxeU46ZwCIsWTc7ais3YySwdq1azVy5Eh16tRJjRs3jtnz0jkDgAfxstsRJ74o3+rVq7VlyxaNHz9eBx98cEyfm84ZAIBS1q5dq/vuu08dOnSIeWGW6JwBADjA0qVLtX37do0fP17169f3koHOGQCAkG3btunvf/+7jjvuOG+FWaJzBpCk4mlGdGnJPLM5kS1YsEDr16/X+PHjo74fc2XonAEkpXieEZ2sM5sTWWFhoV5++WWddtpp3guzROcMIInFy4xoxLc5c+Zo2bJlGjFihO8o+9E5AwBSlnNOs2bN0qWXXuo7ygHonAEAKWnGjBmaN2+e/vCHP/iO8iN0zgCAlLNz505t2bJF119/ve8oZaJzBlBtsZgRXd1jPzMjGuV57733NH/+fN18882+o5SLzhlAtTEjGolm+fLlatasWVwXZonOGUANRXtGNMd+RqT85z//0cqVK/XnP//Zd5RKUZwBAEnv448/Vvfu3XXBBRf4jhIWVmsDAJLatGnTtGTJErVs2dJ3lLDROQMAktYrr7yic845R4cccojvKFVCcQZQ7VnXzIhGPJs+fbry8/MTrjBLrNYGoOrPumZGNOLVE088oS5duuiKK67wHaVa6JwBSOI41Ege8+bNU/PmzdW0aVPfUaqNzhkAkDQeeughHXzwwbrooot8R6kRijMAICmsWrVKnTt31tFHH+07So1RnAEACc05p3vuuUcbN27U2Wef7TtORLDNGUgSNTnONbOukaicc1q9erV++ctfqmvXrr7jRAydM5AkanKca2ZdIxE55zR69GitW7dOPXr08B0nouicgSTCjGukiuLiYs2fP19XXXWV0tPTfceJODpnAEBCcc5p+PDhKi4uTsrCLNE5AwASSGFhoXJycjRkyBClpaX5jhM1dM4AgIQxduxYtW3bNqkLs0TnDCS0kjO0mXGNZJafn6/nn39ew4cPV61ayd9XJv8rBJJYyRnazLhGMnvsscd06qmnpkRhluicgYTHDG0ks927d+tvf/ubBg0a5DtKTKXGTxAAQMJxzun111/XlVde6TtKzFGcAQBxZ/v27Ro0aJB+85vfqFWrVr7jxBzFGQAQV/bs2aMvvvhCQ4cOTZltzKWl5qsGAMSlzZs3a8CAATr55JPVvHlz33G8YUIY4EFNTlJRErtPIZls2rRJK1eu1Lhx49SgQQPfcbyicwY8qMlJKkpi9ykki/Xr12vkyJFKT09P+gOMhIPOGfCEXaCAwPfff6+NGzfqvvvuU8OGDX3HiQt0zgAAbzZs2KB77rlHHTp0oDCXQOcMAPBixYoV2rRpk8aPH6/69ev7jhNX6JwBADG3a9cu/fWvf9Xxxx9PYS4DnTMQA6VnZzPLGqls0aJFWrFihe6//36Zme84cYnOGYiB0rOzmWWNVFVUVKSXXnpJZ555JoW5AnTOQIwwOxup7quvvtK8efN0++23+44S9+icAQBRV1xcrFmzZql3796+oyQEOmcAQFR99tlnmjVrlv7yl7/4jpIw6JwBAFGzfft2bdmyRTfeeKPvKAmFzhmogX2zsPPy8tSkSZNyl2N2NlJRTk6OZs+erYEDB/qOknDonIEaCPcY2czORqpZsmSJmjZtSmGuJjpnoIYyMjI0atQoZWZm+o4CxIW33npLixcv1k033eQ7SsKiOAMAImb69Ok68cQTdd555/mOktBYrQ0AiIh33nlHixYt0mGHHeY7SsKjcwYA1Ngrr7yis846S+ecc47vKEmBzhkAUCOff/65du/ercaNG/uOkjQozgCAanvqqafUvn17XXnllb6jJBWKMwCgWr799ls1btxYLVu29B0l6VCcAQBV9sgjj6ioqEiXXnqp7yhJieIMAKiSdevWKT09XZ06dfIdJWlRnAEAYXHO6f7779fKlSt17rnn+o6T1NiVCqiCfcfS3odjZiNVOOe0Zs0a9ezZUyeddJLvOEmPzhmogtLH0uaY2UgFzjndfffdWrVqlU4++WTfcVICnTNQRRkZGcrJyTngttLXgWThnNPcuXPVp08fHXPMMb7jpAw6ZwBAuUaNGqXCwkIKc4zROQMAfqSoqEjvvfeeBg4cqEaNGvmOk3LonAEAP3Lfffepbdu2FGZP6JwBAPsVFBTomWee0ZAhQ1SrFv2bLxRnJK3Suz1FArtOIdlNnjxZZ5xxBoXZM0YfSav0bk+RwK5TSFZ79uzRmDFjdN111zH5Kw6E1Tmb2XmSHpJUW9Ljzrl7St1/pKR/SmoSWmaoc25aZKMCVVfWbk8ADuSc05tvvql+/frJzHzHgcLonM2stqRHJJ0vqbOk3mbWudRiwyW94JzrKukKSZMiHRQAEHm7d+/WgAED9H//939q06aN7zgICWe19kmSljjnljnn8iU9J+miUss4SfvOsp0m6fvIRQQARMPu3bu1ZMkSDRs2THXqMAUpnoTzbrSWtKrE9dWSepRaZpSkd8zsL5IaSjqrrAcys+slXS9JLVu2PGB1444dO1j9GEWpOL55eXmSYnP0rlQc31hhbKNjx44deuyxx3TVVVdpwYIFWrBgge9ISacmn91I/VTqLWmyc+4BM/u5pKfNrItzrrjkQs65LElZktStWzeXmZm5/76cnByVvI7IStbxrWhG9ooVK5SRkRGT152s4xsPGNvI27x5s1atWqXJkyfrq6++YnyjpCaf3XBWa6+R1LbE9Tah20q6VtILkuSc+1RSA0nNq5UIqIKKZmQzsxr4sY0bN2rEiBFq3769Dj30UN9xUI5wOudZkjqY2VEKivIVkkp/462UdKakyWZ2rILivCGSQYHyMCMbCM+6deu0fv163XPPPRz5K85V2jk75wol3SjpbUkLFczKnm9md5rZhaHFbpX0ezP7StKzkq5xzrlohQYAVM2WLVt01113KT09ncKcAMLa5hzaZ3laqdtGlri8QNIvIhsNABAJK1eu1Pfff68JEyaofv36vuMgDBwhDACS2N69e/XQQw+pa9euFOYEwo5tiHsVzcjmWNdA+b799lstWrRI999/P0f+SjB0zoh7zMgGqs45p5deeknnnXcehTkB0TkjITAjGwjfvHnzNHv2bA0bNsx3FFQTnTMAJJHi4mLNnj1bffv29R0FNUDnDABJYvbs2Zo+fboGDBjgOwpqiM4ZAJLA1q1btXnzZvXv3993FEQAnTO8qGgGdmnMyAYq9tFHH2nGjBkaOnSo7yiIEDpneFHRDOzSmJENlG/RokVq2rSphgwZ4jsKIojOGd4wAxuomffee09ff/0125iTEMUZABLQ9OnTdcIJJ+iss87yHQVRwGptAEgwOTk5WrBggQ477DDfURAldM4AkEBeffVVZWZmKjMz03cURBHFGTFRenY2M7CBqsvNzdW2bdt06KGH+o6CKGO1NmKi9OxsZmADVfP000+rWbNm6tevn+8oiAE6Z8QMs7OB6lm5cqXq16+vtm3b+o6CGKFzBoA49uijj2rLli26/PLLfUdBDFGcASBObdiwQUceeaR++tOf+o6CGKM4A0AcmjhxohYtWqTzzz/fdxR4wDZn1Ei4x8hmdjYQHuec1qxZo1NOOUU9evTwHQee0DmjRsI9Rjazs4HKOec0btw4LV++nMKc4uicUWPMwgZqzjmn3Nxc9e7dW0cddZTvOPCMzhkA4sDdd9+twsJCCjMk0TkDgFfFxcWaNm2aBgwYoIYNG/qOgzhB5wwAHk2YMEHt2rWjMOMAdM4A4EFhYaGeeuop3XrrrTIz33EQZyjOqBJOYAFExjPPPKPTTz+dwowysVobVcIJLICa2bt3r+68807169dPHTt29B0HcYrOGVXGrlNA9Tjn9N5776lfv350zKgQnTMAxMCuXbvUv39/nX322WrXrp3vOIhzFGcAiLLdu3dr7ty5Gjp0qOrVq+c7DhIAxRkAomjbtm0aOHCgOnXqpMMPP9x3HCQItjkDQJRs2bJFK1eu1J133qm0tDTfcZBA6JwBIAo2b96s4cOHq127dmrWrJnvOEgwdM4AEGEbNmzQmjVrNG7cODVu3Nh3HCQgOmcAiKDt27dr9OjRSk9PpzCj2uicASBC1qxZo+XLl2vChAnMykaN0DkDQAQUFhbqoYceUrdu3SjMqDE6ZwCooWXLlumrr77Sfffd5zsKkgSdMwDUgHNOL7/8si644ALfUZBE6JwBoJoWLlyojz76SIMGDfIdBUmGzhkAqqGoqEhffPGFrr32Wt9RkITonAGgir788ku98847GjJkiO8oSFJ0zgBQBVu2bNGWLVtYlY2oojijUllZWcrMzFRmZqZyc3N9xwG8+eSTT/TII4/ojDPOUK1afH0ievh0oVLZ2dn7i3JGRob69OnjNxDgwcKFC3XooYfq9ttv9x0FKYBtzghLRkaGcnJyfMcAvPjwww81c+ZMDRw4UGbmOw5SAMUZACrw4YcfqlOnTjr99NN9R0EKYbU2AJTjk08+0dy5c9WyZUvfUZBi6JwBoAz//ve/dcopp+iUU07xHQUpiM4ZAEpZsGCBNm7cqBYtWviOghRFcQaAEv71r3+pfv36HPkLXlGcASBk3bp1qlWrlo455hjfUZDiKM4AIOnxxx/XqlWr1Lt3b99RAIozAGzevFlHHHGEunfv7jsKIInZ2gBS3MMPP6zjjz9evXr18h0F2I/iDCBlrV69Wj169FCPHj18RwEOwGptACnpnnvu0bfffkthRlyicwaQUpxz+uKLL9SnTx8deeSRvuMAZaJzBpBS7r33XhUUFFCYEdfonAGkhOLiYr3++uu6+eabddBBB/mOA1SIzhlASnjkkUfUrl07CjMSAp0zgKRWVFSkxx57TDfeeCPnYkbCoHMGkNSef/55ZWZmUpiRUOicASSl/Px8jR07ViNHjlStWvQhSCx8YgEkneLiYn344Yfq168fhRkJiU8tgKSye/du9e/fXz179tRRRx3lOw5QLazWBpA0du3apYULF2rw4MHMykZCo3MGkBS2b9+uQYMGqX379mrdurXvOECN0DknsaysLGVnZ0uS8vLy1KRJk2o9Tm5urjIyMiIXDIiwrVu3asWKFRo1apSaNWvmOw5QY3TOSSw7O1u5ubk1fpyMjAz16dOn5oGAKMjLy9OwYcPUtm1btWjRwnccICLonJNcRkaGcnJylJOTo8zMTN9xgIjauHGjVq5cqXHjxiktLc13HCBi6JwBJKTdu3dr1KhR6tChA4UZSYfOGUDCWbt2rRYuXKiJEyeqbt26vuMAEUfnDCChFBcX68EHH9TJJ59MYUbSonMGkDBWrFihzz77TPfee6/vKEBUhdU5m9l5ZrbIzJaY2dBylrnczBaY2Xwzy45sTACQXnnlFV1yySW+YwBRV2nnbGa1JT0i6WxJqyXNMrOpzrkFJZbpIGmYpF8457aY2WHRCgwg9SxatEjvvvuuBgwY4DsKEBPhdM4nSVrinFvmnMuX9Jyki0ot83tJjzjntkiSc+6HyMYEkKqKioo0Z84c/fGPf/QdBYiZcIpza0mrSlxfHbqtpI6SOprZDDP7zMzOi1RAAKnr66+/VnZ2tnr37q06dZgig9QRqU97HUkdJGVKaiNpupkd75zLK7mQmV0v6XpJatmypXJycvbft2PHjgOuo+by8vIkSTk5OYxvlDG+kbd161YtX75cF110EWMbRXx2o6cmYxtOcV4jqW2J621Ct5W0WtLnzrkCScvNbLGCYj2r5ELOuSxJWZLUrVs3V/KIVRzBqnwlj5FdFStWrFBGRoYyMzMZ3yhjfCNr5syZ+uCDDzR69GjGNsoY3+ipydiGs1p7lqQOZnaUmdWTdIWkqaWWeU1B1ywza65gNfeyaiXCj1T3GNkcExuJaP78+UpLS9OoUaN8RwG8qbRzds4VmtmNkt6WVFvSk865+WZ2p6TZzrmpofvOMbMFkookDXLObYpm8FSz7xjZQDKbMWOGpk+frqFDh8rMfMcBvAlrm7NzbpqkaaVuG1nispM0IPQPAKps+vTp6tixo0455RQKM1Ieh+8E4N3s2bM1Z84cHX744RRmQBRnAJ69/vrratWqlW655RbfUYC4QXEG4M3SpUu1du1atWrVyncUIK5QnAF48fzzz2vv3r26/vrrfUcB4g7FGUDMbdq0SYWFhercubPvKEBc4nh4AGJq8uTJSk9P15VXXuk7ChC36JwBxMzWrVvVokUL9ezZ03cUIK7ROQOIiUmTJik9PV29evXyHQWIexRnAFG3atUqde/eXd27d/cdBUgIFOcIqu4JKiqTm5urjIyMiD8uEAsPPPCATjjhBJ199tm+owAJg23OEVTdE1RUhhNYIBE55/T555/riiuuoDADVUTnHGGcoAIITJgwQSeffLJat27tOwqQcCjOACLKOadXX31VN9xwgxo0aOA7DpCQWK0NIKKysrLUrl07CjNQA3TOACKiqKhIkyZN0o033siZpYAaojhXUUUzsplVjVT2yiuv6IwzzqAwAxHAau0qqmhGNrOqkYoKCgo0YsQIXXzxxTruuON8xwGSAp1zNTAjGwgUFxdrxowZ6tevn+rU4esEiBQ6ZwDVsmfPHvXv318/+9nPlJ6e7jsOkFT4qQugynbv3q1FixZp4MCBatSoke84QNKhcwZQJTt37tSgQYPUqlUrtW3b1nccICnROQMI2/bt27V8+XKNGDFChx12mO84QNKicwYQlu3bt2vo0KFq1aqVWrZs6TsOkNTonAFUavPmzVq2bJnGjh2rtLQ033GApEfnDKBC+fn5GjlypDp06EBhBmKEzhlAudavX6/c3Fw9+OCD7McMxBCdM4AyOef08MMPq2fPnhRmIMZS9v+4io6RXRGOn41UsGrVKuXk5GjMmDG+owApKWU754qOkV0Rjp+NVPDaa6/psssu8x0DSFkp2zlLHCMbKG3p0qWaOnWq+vfv7zsKkNJStnMGcKCCggLNmTNHN954o+8oQMpL6c4ZQGD+/Pl64YUXNHr0aN9RAIjOGUh5P/zwg/Ly8jRy5EjfUQCEUJyBFPbFF1/o4Ycf1imnnKLatWv7jgMghOIMpKh58+apUaNGuuuuu2RmvuMAKIHiDKSgmTNn6rXXXlOHDh0ozEAcojgDKeajjz5SmzZtdPvtt1OYgThFcQZSyNdff62ZM2eqVatWFGYgjlGcgRQxbdo0paWl6dZbb/UdBUAlKM5ACli1apVWrFihdu3a+Y4CIAwUZyDJvfTSS9q0aZP+/Oc/+44CIEwUZyCJbd26Vbt37+ZMakCC4fCdQJJ6+umn1bp1a1199dW+owCoIjpnIAlt27ZNzZo10xlnnOE7CoBqoHMGksyjjz6qNm3aqFevXr6jAKgmijOQRL777jt169ZNP/vZz3xHAVADSV2cs7KylJ2dXeZ9ubm5TJJBUnnooYfUsWNHnX/++b6jAKihpC7O2dnZ5RbhjIwM9enTJ/ahgAhzzumTTz7R5ZdfriOOOMJ3HAARkNTFWQqKcE5Oju8YQNQ8/PDDysjIoDADSSTpizOQrJxzevHFF/XHP/5R9evX9x0HQASxKxWQoJ566im1a9eOwgwkITpnIMEUFxfr4Ycf1s0338yZpYAklfDFmRnZSDX/+c9/dMYZZ1CYgSSW8Ku1983ILgszspFMCgsLNWLECJ177rk64YQTfMcBEEUJ3zlLzMhG8isqKtLMmTN19dVXs40ZSAEJ3zkDyS4/P18DBw7Uscceq44dO/qOAyAGkqJzBpLVnj17tHjxYt1yyy069NBDfccBECN0zkCc2rVrlwYNGqQWLVqoXbt2vuMAiCE6ZyAO7dy5U0uXLtVtt93Gkb+AFETnDMSZnTt3avDgwTr88MMpzECKonMG4kheXp4WLVqksWPHKi0tzXccAJ7QOQNxorCwUCNHjlTHjh0pzECKo3MG4sCGDRv0+eefa+LEiapdu7bvOAA8o3MGPHPO6W9/+5syMzMpzAAkJWDnXPpY2hw/G4lszZo1evvttzV69GjfUQDEkYTrnEsfS5vjZyNROec0depU9e7d23cUAHEm4TpniWNpI/EtX75czz//vIYOHeo7CoA4lHCdM5Do9u7dq9zcXA0YMMB3FABxiuIMxNDChQs1evRoXXzxxapXr57vOADiFMUZiJF169Zp69atuuuuu3xHARDnKM5ADOTm5uqhhx7SSSedxO5SACpFcQaibN68eWrYsKHGjBmjWrX4Xw5A5fimAKJozpw5eumll5Senk5hBhA2vi2AKJkxY4aaN2+uO+64Q2bmOw6ABEJxBqLgm2++0ccff6y2bdtSmAFUGcUZiLB33nlHtWrV0pAhQyjMAKolrOJsZueZ2SIzW2Jm5R7SyMwuNTNnZt0iFxFIHOvXr9c333yjjh07+o4CIIFVWpzNrLakRySdL6mzpN5m1rmM5RpJulnS55EOCSSC1157TStWrNBNN93kOwqABBdO53ySpCXOuWXOuXxJz0m6qIzl7pJ0r6Q9EcwHJITdu3dr27Zt6tGjh+8oAJJAOMW5taRVJa6vDt22n5mdKKmtc+6NCGYDEsKzzz6ruXPnqm/fvr6jAEgSNT4rlZnVkjRB0jVhLHu9pOslqWXLlgecWWrHjh1hnWkqLy9PkjgrVRWFO76omp07d+q7775Tly5dGN8o4bMbXYxv9NRkbMMpzmsktS1xvU3otn0aSeoiKSc0M/VwSVPN7ELn3OySD+Scy5KUJUndunVzmZmZ++/LyclRyevladKkiSSFtSz+J9zxRfiefPJJNW3aVEOHDmV8o4ixjS7GN3pqMrbhFOdZkjqY2VEKivIVkvrsu9M5t1VS833XzSxH0sDShRlIJsuWLdOJJ56ojIwM31EAJKFKtzk75wol3SjpbUkLJb3gnJtvZnea2YXRDgjEm0ceeUTz58+nMAOImrC2OTvnpkmaVuq2keUsm1nzWEB8+uijj3TZZZfpsMMO8x0FQBLjCGFAmP7+97+roKCAwgwg6mo8WxtIds45Pffcc7ruuutUt25d33EApAA6Z6AS2dnZat++PYUZQMzQOQPlKC4u1oMPPqibb75ZtWvX9h0HQAqhcwbK8c477+iXv/wlhRlAzFGcgVKKioo0fPhwnXbaaeratavvOABSEMUZKKGoqEhz5szRlVdeqYMPPth3HAApiuIMhBQUFGjQoEFq166djj32WN9xAKQwJoQBkvbu3atvv/1WN954I/sxA/COzhkpb8+ePRo0aJCaNGmio48+2nccAEiM4pyVlaXMzExlZmYqNzfXdxwkkV27dmnx4sUaOnSo2rRp4zsOAEhKkOKcnZ29vyhnZGSoT58+Ff8BEIY9e/Zo8ODBOuyww9SqVSvfcQBgv4TZ5pyRkcEJwREx27Zt09y5czV27Fg1btzYdxwAOEBCdM5AJBUXF2vEiBHq1KkThRlAXEqYzhmIhE2bNmn69OmaOHGiatXitymA+MS3E1LKpEmTdOaZZ1KYAcQ1OmekhHXr1unf//63RowY4TsKAFSK9gFJzzmn119/XVdffbXvKAAQFjpnJLXvvvtOU6ZMoWMGkFDonJG09uzZo6+//lqDBw/2HQUAqoTijKS0ePFijRw5UhdccIHq16/vOw4AVAnFGUnn+++/19atWzV27FiZme84AFBlcbnNOSsrS9nZ2fuv5+bmKiMjw18gJIy5c+fqmWee0dixY1W7dm3fcQCgWuKycy55LG2J42kjPPPmzVODBg00btw4CjOAhBaXnbPEsbRRNfPmzdMLL7ygUaNGcYARAAmPbzEkvE8//VQNGzbU6NGjKcwAkgLfZEhoy5Yt0wcffKD27dsz+QtA0qA4I2H997//1a5duzRs2DAKM4CkQnFGQtq8ebPmzZunLl26UJgBJJ24nRAGlOc///mP0tLSdPPNN/uOAgBRQeeMhLJnzx5t3rxZp556qu8oABA1dM5IGC+88IIaNGigvn37+o4CAFFFcUZC2LZtmxo3bqzzzjvPdxQAiDqKM+LeP//5Tx188MG67LLLfEcBgJigOCOuffvttzrxxBN1/PHH+44CADHDhDDErUcffVQLFiygMANIOXTOiEsffPCBLr30UjVv3tx3FACIOTpnxJ3HH39cBQUFFGYAKYvOGXHDOadnnnlG11xzjerU4aMJIHXROSNuvPTSS2rfvj2FGUDK41sQ3jnnNGHCBN10002qW7eu7zgA4B2dM7z74IMPdPrpp1OYASCE4gxviouLNXz4cHXr1k3dunXzHQcA4garteFFUVGR5s6dqyuuuEKNGzf2HQcA4gqdM2KuoKBAQ4YMUYsWLdSlSxffcQAg7tA5I6by8/O1ZMkS/eEPf1Dr1q19xwGAuETnjJjZu3evBg8erIMPPlgdOnTwHQcA4hadM2Ji9+7dWrx4sQYNGkTHDACVoHNG1BUUFGjQoEFq3rw5hRkAwkDnjKjavn275syZo3HjxqlRo0a+4wBAQqBzRtQ45zRq1Ch17tyZwgwAVUDnjKjYsmWL3n33XY0fP161avEbEACqgm9NREVWVpbOOeccCjMAVAOdMyLqhx9+0AsvvKAhQ4b4jgIACYu2BhHjnNMbb7yh3/72t76jAEBCo3NGRKxevVpZWVm68847fUcBgIRH54wa2717t+bNm6fbbrvNdxQASAoUZ9TI0qVLdfvtt+vcc89VgwYNfMcBgKRAcUa1rV69Wlu3btW9994rM/MdBwCSBsUZ1bJw4UI9/PDDOuGEE1S3bl3fcQAgqVCcUWXz589XnTp1NG7cONWpw5xCAIg0ijOq5JtvvlF2draOOeYY1a5d23ccAEhKFGeEbebMmapdu7buvvtujvwFAFHENyzCsnr1ar311ltKT09n8hcARBkbDFGpDz/8UI0aNdKIESMozAAQA3TOqND27dv15ZdfqmvXrhRmAIiRuOics7KyNGnSJDVp0kSSlJubq4yMDK+ZIL355puqW7eubrnlFt9RACClxEXnnJ2drSVLluy/npGRoT59+nhMhPz8fG3YsEFnnXWW7ygAkHLionOWpPT0dOXk5PiOAUmvvPKKiouL1bdvX99RACAlxU1xRnzYunWrDjnkEJ1zzjm+owBAyqI4Y79nnnlGtWrVYpMCAHhGcYak4MhfJ554ojp37uw7CgCkvLiYEAa/nnjiCc2fP5/CDABxgs45xf33v//VxRdfrKZNm/qOAgAIoXNOYVOmTNHevXspzAAQZ+icU9SUKVPUp08fTvkIAHGIzjkFTZ06VUceeSSFGQDiVFjF2czOM7NFZrbEzIaWcf8AM1tgZl+b2X/NrF3ko6KmnHN64IEHdO655yozM9N3HABAOSotzmZWW9Ijks6X1FlSbzMrPa33S0ndnHMnSHpJ0n2RDoqamzFjhnr27Kn69ev7jgIAqEA4nfNJkpY455Y55/IlPSfpopILOOc+cM7tCl39TFKbyMZETRQXF+vJJ5/Uscceqx49eviOAwCoRDgbHVtLWlXi+mpJFX3DXyvpzbLuMLPrJV0vSS1bttx/LO28vDwVFRVxbO0oKCoq0sqVK9W9e3fNnTvXd5yktWPHDj6/UcLYRhfjGz01GduIzggys6skdZN0eln3O+eyJGVJUrdu3dy+7Z5NmjRRXl4e20EjrLCwULfddptuuOEGLV++nPGNopycHMY3Shjb6GJ8o6cmYxvOau01ktqWuN4mdNsBzOwsSbdLutA5t7daaRAxBQUFWrJkia699lq1a8f8PABIJOEU51mSOpjZUWZWT9IVkqaWXMDMukp6VEFh/iHyMVEV+fn5Gjx4sOrWrauf/OQnvuMAAKqo0tXazrlCM7tR0tuSakt60jk338zulDTbOTdV0nhJh0h60cwkaaVz7sIo5kY59uzZo2+++UYDBw5U69atfccBAFRDWNucnXPTJE0rddvIEpfPinAuVENRUZEGDx6sQYMGUZgBIIFxiKgksXPnTn322WcaN26cGjZs6DsOAKAGOHxnkrjzzjvVpUsXCjMAJAE65wSXl5enN954Q/fcc49C2/sBAAmOzjnBPfHEEzr//PMpzACQROicE9TGjRs1ZcoU3Xrrrb6jAAAijM45ATnn9NZbb+n3v/+97ygAgCigOCeY77//XrfddpuuuuoqNWrUyHccAEAUUJwTyM6dO7VgwQKNHDmy8oUBAAmL4pwgVqxYodtuu01nnHGGDjroIN9xAABRRHFOAKtXr1ZeXp7Gjx+vWrV4ywAg2fFNH+cWL16siRMn6rjjjlO9evV8xwEAxADFOY4tWLBAknTvvfeqbt26ntMAAGKF4hynli5dqilTpuiYY45RnTrsjg4AqYTiHIe++OIL7d27V2PHjlXt2rV9xwEAxBjFOc788MMPev3113Xssccy+QsAUhTrS+PIxx9/rDp16mjUqFG+owAAPKI1ixO7d+/WrFmz1KNHD99RAACe0TnHgXfffVf5+fnq37+/7ygAgDhA5+xZQUGB1q9fr169evmOAgCIE3TOHk2dOlU7duzQVVdd5TsKACCOUJw92bJlixo2bKgLL7zQdxQAQJyhOHvw3HPPKT8/X3379vUdBQAQhyjOMTZ//nx17dpVP/nJT3xHAQDEKSaExdCUKVM0f/58CjMAoEJ0zjHyzjvv6KKLLlJaWprvKACAOEfnHAPPPfec9u7dS2EGAISFzjnKJk+erCuvvJJTPgIAwkbnHEVvvfWW2rRpQ2EGAFQJnXMUOOf0wAMP6E9/+pMaNmzoOw4AIMHQOUeYc06zZs3Sz3/+cwozAKBaKM4RVFxcrDvuuENHHnmkfvGLX/iOAwBIUBTnCCkuLtbixYv161//WocffrjvOACABEZxjoCioiINGzZMderU0Yknnug7DgAgwTEhrIYKCwu1dOlS/fa3v1V6errvOACAJEDnXAMFBQUaPHiwzEydOnXyHQcAkCTonKtp7969mj9/vm699Va1bt3adxwAQBKhc66G4uJiDRkyRM2aNaMwAwAijs65inbt2qXp06dr3LhxOuigg3zHAQAkITrnKhozZox++tOfUpgBAFFD5xymbdu26dVXX9Xdd98tM/MdBwCQxOicw/TUU0+pV69eFGYAQNTROVdi8+bNevzxxzV48GDfUQAAKYLOuQLFxcV699139Yc//MF3FABACqE4l2PdunUaMmSILr/8cqWlpfmOAwBIIRTnMmzfvl3ffPONRo0axTZmAEDMUZxLWblypW677Tb17NmT8zEDALygOJewatUq5eXl6f7771edOsyVAwD4QXEOWbp0qSZOnKhOnTqpfv36vuMAAFIY7aGkb775RpJ07733qm7dup7TAABSXcp3zitXrtRTTz2lDh06UJgBAHEhpTvn3Nxc1apVS+PGjVOtWin/OwUAECdStiLl5eXp1VdfVZcuXSjMAIC4kpKd82effab8/HyNHj3adxQAAH4k5VrG/Px8ffrppzr11FN9RwEAoEwp1Tm///77ysvLU//+/X1HAQCgXCnTORcUFGjt2rW65JJLfEcBAKBCKdE5v/HGG9qwYYOuueYa31EAAKhU0hfnjRs3qmHDhurVq5fvKAAAhCWpi/OLL76o7du363e/+53vKAAAhC1pi/PXX3+trl27Kj093XcUAACqJCknhD377LOaO3cuhRkAkJCSrnN+88031atXLzVu3Nh3FAAAqiWpivPLL7+sWrVqUZgBAAktaYrz5MmT1bt3b87FDABIeEmxzfn999/X4YcfTmEGACSFhO6cnXOaMGGCrrvuOqWlpfmOAwBARCRs5+yc09dff63u3btTmAEASSUhi7NzTnfddZcOPfRQnXbaab7jAAAQUQm3Wru4uFjLli3T+eefryOPPNJ3HAAAIi6hOufi4mINHz5cBQUF6t69u+84AABERcJ0zkVFRVq6dKmuuuoqHXvssb7jAAAQNQnRORcWFmrIkCEqKipS586dfccBACCq4r5zLigo0FdffaVbb71VRxxxhO84AABEXVx3zs45DR06VE2bNqUwAwBSRtx2znv27NF7772nMWPGqEGDBr7jAAAQM3HbOd93333q2rUrhRkAkHLCKs5mdp6ZLTKzJWY2tIz765vZ86H7Pzez9tUNtGPHDj3xxBMaMWKEWrduXd2HAQAgYVVanM2stqRHJJ0vqbOk3mZWesr0tZK2OOfSJU2UdG91Az399NO68MILZWbVfQgAABJaOJ3zSZKWOOeWOefyJT0n6aJSy1wk6Z+hyy9JOtOqWF0LCws1ZswY/elPf1KLFi2q8qcAACSVcIpza0mrSlxfHbqtzGWcc4WStkpqVpUgO3bs0A033FCVPwEAICnFdLa2mV0v6XpJatmypXJyciRJzZs3V1pamnJzc2MZJ6Xs2LFj/3gj8hjf6GFso4vxjZ6ajG04xXmNpLYlrrcJ3VbWMqvNrI6kNEmbSj+Qcy5LUpYkdevWzWVmZkqSMjMzlZOTo33XEXmMb3QxvtHD2EYX4xs9NRnbcFZrz5LUwcyOMrN6kq6QNLXUMlMl9Qtd/o2k951zrlqJAABIcZV2zs65QjO7UdLbkmpLetI5N9/M7pQ02zk3VdITkp42syWSNiso4AAAoBrMV4NrZhskfVfipuaSNnoJkxoY3+hifKOHsY0uxjd6So9tO+dcWLsjeSvOpZnZbOdcN985khXjG12Mb/QwttHF+EZPTcY2bg/fCQBAqqI4AwAQZ+KpOGf5DpDkGN/oYnyjh7GNLsY3eqo9tnGzzRkAAATiqXMGAADyUJxjefrJVBTG+A4wswVm9rWZ/dfM2vnImYgqG9sSy11qZs7MmAFbBeGMr5ldHvr8zjez7FhnTFRhfC8caWYfmNmXoe+GX/nImYjM7Ekz+8HM5pVzv5nZw6Gx/9rMTgzrgZ1zMfun4CAmSyUdLamepK8kdS61zJ8l/SN0+QpJz8cyYyL/C3N8fynp4NDlPzG+kRvb0HKNJE2X9Jmkbr5zJ8q/MD+7HSR9KenQ0PXDfOdOhH9hjm2WpD+FLneWtMJ37kT5J+k0SSdKmlfO/b+S9KYkk3SypM/DedxYd84xOf1kCqt0fJ1zHzjndoWufqbgWOmoXDifXUm6S8H5zPfEMlwSCGd8fy/pEefcFklyzv0Q44yJKpyxdZIahy6nSfo+hvkSmnNuuoIjY5bnIklTXOAzSU3M7IjKHjfWxTkmp59MYeGMb0nXKvhFh8pVOrah1VVtnXNvxDJYkgjns9tRUkczm2Fmn5nZeTFLl9jCGdtRkq4ys9WSpkn6S2yipYSqfi9LivEpIxE/zOwqSd0kne47SzIws1qSJki6xnOUZFZHwartTAVrfKab2fHOuTyfoZJEb0mTnXMPmNnPFZwroYtzrth3sFQV6865KqefVEWnn0SZwhlfmdlZkm6XdKFzbm+MsiW6ysa2kaQuknLMbIWCbUtTmRQWtnA+u6slTXXOFTjnlktarKBYo2LhjO21kl6QJOfcp5IaKDguNGourO/l0mJdnDn9ZHRVOr5m1lXSowoKM9vswlfh2Drntjrnmjvn2jvn2ivYnn+hc262n7gJJ5zvhtcUdM0ys+YKVnMvi2HGRBXO2K6UdKYkmdmxCorzhpimTF5TJfUNzdo+WdJW59zayv4opqu1HaefjKowx3e8pEMkvRiaZ7fSOXeht9AJIsyxRTWFOb5vSzrHzBZIKpI0yDnHWrVKhDm2t0p6zMz6K5gcdg1NUXjM7FkFPxqbh7bZ3yGpriQ55/6hYBv+ryQtkbRL0m/DelzGHwCA+MIRwgAAiDMUZwAA4gzFGQCAOENxBgAgzlCcAQCIMxRnAADiDMUZAIA4Q3EGACDO/H8XYM/b+jjqLAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x204b96af7f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7639 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7639 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7639 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7639 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7639 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7639 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7639 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7639 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7639 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7639 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7639 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7639 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7656 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7656 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7656 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7656 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7656 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7656 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7639 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7656 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7656 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7656 - val_loss: 0.4930 - val_accuracy: 0.7656\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7639 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7639 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7639 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7639 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7656 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7656 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7639 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7656 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7656 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7656 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7639 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7639 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7656 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7639 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7639 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7639 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7639 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7639 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7639 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7639 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7639 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7639 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7639 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7639 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7639 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7639 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7639 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7639 - val_loss: 0.4912 - val_accuracy: 0.7656\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7639 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7639 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7639 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7639 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7639 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7639 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7639 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7639 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7639 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7639 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7639 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7639 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7639 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7639 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7639 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7622 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7622 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7622 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7622 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7622 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7622 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7622 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7639 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7639 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7639 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7639 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7639 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7639 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7639 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7639 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7639 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7639 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7639 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7639 - val_loss: 0.4896 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7639 - val_loss: 0.4896 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7639 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7639 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7639 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7639 - val_loss: 0.4894 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7639 - val_loss: 0.4894 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7639 - val_loss: 0.4893 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7639 - val_loss: 0.4893 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7639 - val_loss: 0.4893 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7639 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7639 - val_loss: 0.4892 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7639 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7639 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7656 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7656 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7639 - val_loss: 0.4890 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7656 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7656 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.4889 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7656 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7656 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7656 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7639 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7639 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.7639 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7639 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7639 - val_loss: 0.4886 - val_accuracy: 0.7604\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7622 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7622 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7622 - val_loss: 0.4885 - val_accuracy: 0.7604\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7639 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7622 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7622 - val_loss: 0.4884 - val_accuracy: 0.7604\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7622 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7622 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7622 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7622 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7622 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7622 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7622 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7622 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7622 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7622 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.84 - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7622 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7622 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7622 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7622 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7622 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7622 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7622 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7622 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7622 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7622 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7622 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7622 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7622 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7622 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7622 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7622 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7622 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7622 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7622 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7622 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7622 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7622 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7622 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7622 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7622 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7622 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7622 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7622 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7622 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7622 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7622 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7622 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7622 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7622 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7622 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7622 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7622 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7622 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7622 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7622 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7622 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7622 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7622 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7622 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7622 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7622 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7622 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7622 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7622 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7622 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7622 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7622 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7622 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7622 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7622 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7622 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7622 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7622 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7622 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7622 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7622 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7622 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7639 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7604 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7622 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7622 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7622 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7622 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7622 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7622 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7622 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7622 - val_loss: 0.4860 - val_accuracy: 0.7656\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7622 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7622 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7622 - val_loss: 0.4859 - val_accuracy: 0.7656\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7622 - val_loss: 0.4858 - val_accuracy: 0.7656\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7622 - val_loss: 0.4858 - val_accuracy: 0.7656\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7622 - val_loss: 0.4858 - val_accuracy: 0.7656\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7622 - val_loss: 0.4858 - val_accuracy: 0.7656\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7622 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7622 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7639 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7639 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7639 - val_loss: 0.4857 - val_accuracy: 0.7656\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7639 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7639 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7639 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7639 - val_loss: 0.4856 - val_accuracy: 0.7656\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7639 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7639 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7639 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7639 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7639 - val_loss: 0.4855 - val_accuracy: 0.7656\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7656 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7639 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7639 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7656 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7656 - val_loss: 0.4854 - val_accuracy: 0.7656\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7639 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7639 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7656 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7656 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7656 - val_loss: 0.4853 - val_accuracy: 0.7656\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7639 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7656 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7639 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7656 - val_loss: 0.4852 - val_accuracy: 0.7656\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7656 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7656 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7656 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7656 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7656 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7656 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7656 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7656 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7639 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7656 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7656 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7656 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7639 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7656 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7656 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7656 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7656 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7656 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7639 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7656 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7656 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7656 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7656 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7656 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7674 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7656 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7674 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7674 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7604\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4841 - val_accuracy: 0.7604\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4841 - val_accuracy: 0.7604\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7708 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7708 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7708 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4840 - val_accuracy: 0.7604\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7604\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4838 - val_accuracy: 0.7604\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.4837 - val_accuracy: 0.7604\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4836 - val_accuracy: 0.7604\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4835 - val_accuracy: 0.7604\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.71 - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4834 - val_accuracy: 0.7604\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4833 - val_accuracy: 0.7604\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4832 - val_accuracy: 0.7604\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4831 - val_accuracy: 0.7604\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4830 - val_accuracy: 0.7552\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7743 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.7552\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7743 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4828 - val_accuracy: 0.7552\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4827 - val_accuracy: 0.7552\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7552\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4827 - val_accuracy: 0.7552\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4827 - val_accuracy: 0.7604\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7604\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7743 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4825 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4824 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4823 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4822 - val_accuracy: 0.7604\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.71 - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7604\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4819 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.77 - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.87 - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4820 - val_accuracy: 0.7604\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.62 - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.4821 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x204b97697f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 10ms/step - loss: 0.7649 - accuracy: 0.6389 - val_loss: 0.7936 - val_accuracy: 0.6146\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7531 - accuracy: 0.6372 - val_loss: 0.7819 - val_accuracy: 0.6146\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.6372 - val_loss: 0.7713 - val_accuracy: 0.6146\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.6372 - val_loss: 0.7617 - val_accuracy: 0.6094\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.6372 - val_loss: 0.7529 - val_accuracy: 0.6146\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.6354 - val_loss: 0.7448 - val_accuracy: 0.6146\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7073 - accuracy: 0.6354 - val_loss: 0.7373 - val_accuracy: 0.6146\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.6354 - val_loss: 0.7305 - val_accuracy: 0.6146\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.6337 - val_loss: 0.7241 - val_accuracy: 0.6146\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.6354 - val_loss: 0.7181 - val_accuracy: 0.6146\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.6337 - val_loss: 0.7125 - val_accuracy: 0.6146\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.6319 - val_loss: 0.7073 - val_accuracy: 0.6198\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6302 - val_loss: 0.7025 - val_accuracy: 0.6146\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6302 - val_loss: 0.6979 - val_accuracy: 0.6094\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6319 - val_loss: 0.6936 - val_accuracy: 0.6094\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6337 - val_loss: 0.6895 - val_accuracy: 0.6094\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6354 - val_loss: 0.6856 - val_accuracy: 0.6094\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6337 - val_loss: 0.6819 - val_accuracy: 0.6094\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6337 - val_loss: 0.6783 - val_accuracy: 0.6146\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6441 - val_loss: 0.6748 - val_accuracy: 0.6198\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6476 - val_loss: 0.6715 - val_accuracy: 0.6198\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6476 - val_loss: 0.6683 - val_accuracy: 0.6198\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6458 - val_loss: 0.6652 - val_accuracy: 0.6198\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6458 - val_loss: 0.6622 - val_accuracy: 0.6198\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6458 - val_loss: 0.6594 - val_accuracy: 0.6198\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6458 - val_loss: 0.6567 - val_accuracy: 0.6198\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6476 - val_loss: 0.6542 - val_accuracy: 0.6250\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6476 - val_loss: 0.6518 - val_accuracy: 0.6198\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6458 - val_loss: 0.6495 - val_accuracy: 0.6198\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6458 - val_loss: 0.6472 - val_accuracy: 0.6198\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6493 - val_loss: 0.6450 - val_accuracy: 0.6198\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6476 - val_loss: 0.6429 - val_accuracy: 0.6198\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6476 - val_loss: 0.6408 - val_accuracy: 0.6354\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6493 - val_loss: 0.6389 - val_accuracy: 0.6354\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.6493 - val_loss: 0.6370 - val_accuracy: 0.6354\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6493 - val_loss: 0.6351 - val_accuracy: 0.6354\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.6510 - val_loss: 0.6334 - val_accuracy: 0.6354\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6510 - val_loss: 0.6316 - val_accuracy: 0.6458\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6493 - val_loss: 0.6299 - val_accuracy: 0.6510\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6510 - val_loss: 0.6282 - val_accuracy: 0.6562\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6510 - val_loss: 0.6266 - val_accuracy: 0.6562\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6510 - val_loss: 0.6250 - val_accuracy: 0.6667\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.6510 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6545 - val_loss: 0.6220 - val_accuracy: 0.6719\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6580 - val_loss: 0.6205 - val_accuracy: 0.6719\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6562 - val_loss: 0.6191 - val_accuracy: 0.6771\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.6562 - val_loss: 0.6176 - val_accuracy: 0.6771\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6562 - val_loss: 0.6162 - val_accuracy: 0.6771\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6562 - val_loss: 0.6148 - val_accuracy: 0.6719\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.6562 - val_loss: 0.6135 - val_accuracy: 0.6771\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.6545 - val_loss: 0.6122 - val_accuracy: 0.6771\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6545 - val_loss: 0.6109 - val_accuracy: 0.6771\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6580 - val_loss: 0.6096 - val_accuracy: 0.6719\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.6580 - val_loss: 0.6084 - val_accuracy: 0.6771\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.6580 - val_loss: 0.6072 - val_accuracy: 0.6823\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.6580 - val_loss: 0.6061 - val_accuracy: 0.6823\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.6562 - val_loss: 0.6049 - val_accuracy: 0.6823\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.6580 - val_loss: 0.6038 - val_accuracy: 0.6875\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6580 - val_loss: 0.6027 - val_accuracy: 0.6823\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.6597 - val_loss: 0.6017 - val_accuracy: 0.6823\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.6597 - val_loss: 0.6007 - val_accuracy: 0.6771\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.6597 - val_loss: 0.5997 - val_accuracy: 0.6771\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.6615 - val_loss: 0.5986 - val_accuracy: 0.6667\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5638 - accuracy: 0.6632 - val_loss: 0.5976 - val_accuracy: 0.6615\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5627 - accuracy: 0.6684 - val_loss: 0.5967 - val_accuracy: 0.6615\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5617 - accuracy: 0.6649 - val_loss: 0.5957 - val_accuracy: 0.6667\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5607 - accuracy: 0.6649 - val_loss: 0.5948 - val_accuracy: 0.6667\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5597 - accuracy: 0.6649 - val_loss: 0.5939 - val_accuracy: 0.6667\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.6649 - val_loss: 0.5930 - val_accuracy: 0.6667\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.6701 - val_loss: 0.5921 - val_accuracy: 0.6667\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.6701 - val_loss: 0.5912 - val_accuracy: 0.6615\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.6684 - val_loss: 0.5904 - val_accuracy: 0.6667\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.6701 - val_loss: 0.5895 - val_accuracy: 0.6667\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.6684 - val_loss: 0.5887 - val_accuracy: 0.6667\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.6719 - val_loss: 0.5878 - val_accuracy: 0.6667\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.6719 - val_loss: 0.5870 - val_accuracy: 0.6667\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.6753 - val_loss: 0.5862 - val_accuracy: 0.6719\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.6788 - val_loss: 0.5854 - val_accuracy: 0.6719\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.6806 - val_loss: 0.5846 - val_accuracy: 0.6719\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.62 - 0s 3ms/step - loss: 0.5490 - accuracy: 0.6858 - val_loss: 0.5839 - val_accuracy: 0.6719\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.6875 - val_loss: 0.5831 - val_accuracy: 0.6719\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.6875 - val_loss: 0.5823 - val_accuracy: 0.6719\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.6858 - val_loss: 0.5816 - val_accuracy: 0.6719\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.6892 - val_loss: 0.5809 - val_accuracy: 0.6771\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.6875 - val_loss: 0.5802 - val_accuracy: 0.6667\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.6892 - val_loss: 0.5795 - val_accuracy: 0.6719\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.6927 - val_loss: 0.5788 - val_accuracy: 0.6719\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.6927 - val_loss: 0.5782 - val_accuracy: 0.6771\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.6962 - val_loss: 0.5776 - val_accuracy: 0.6823\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7014 - val_loss: 0.5770 - val_accuracy: 0.6823\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7014 - val_loss: 0.5764 - val_accuracy: 0.6875\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7014 - val_loss: 0.5758 - val_accuracy: 0.6823\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.6997 - val_loss: 0.5752 - val_accuracy: 0.6875\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.6997 - val_loss: 0.5746 - val_accuracy: 0.6875\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7031 - val_loss: 0.5740 - val_accuracy: 0.6875\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.6997 - val_loss: 0.5735 - val_accuracy: 0.6875\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.6997 - val_loss: 0.5729 - val_accuracy: 0.6875\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.6997 - val_loss: 0.5724 - val_accuracy: 0.6927\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.6997 - val_loss: 0.5718 - val_accuracy: 0.6927\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7014 - val_loss: 0.5713 - val_accuracy: 0.6927\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.6997 - val_loss: 0.5708 - val_accuracy: 0.6979\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.6997 - val_loss: 0.5702 - val_accuracy: 0.6979\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7066 - val_loss: 0.5697 - val_accuracy: 0.6979\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7049 - val_loss: 0.5692 - val_accuracy: 0.6979\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7101 - val_loss: 0.5687 - val_accuracy: 0.6979\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7083 - val_loss: 0.5682 - val_accuracy: 0.6979\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7101 - val_loss: 0.5676 - val_accuracy: 0.6927\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7083 - val_loss: 0.5672 - val_accuracy: 0.6927\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7118 - val_loss: 0.5667 - val_accuracy: 0.6927\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7101 - val_loss: 0.5662 - val_accuracy: 0.6979\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7101 - val_loss: 0.5657 - val_accuracy: 0.6979\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7118 - val_loss: 0.5652 - val_accuracy: 0.6979\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7118 - val_loss: 0.5647 - val_accuracy: 0.6979\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7118 - val_loss: 0.5643 - val_accuracy: 0.6979\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7135 - val_loss: 0.5638 - val_accuracy: 0.7031\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7118 - val_loss: 0.5633 - val_accuracy: 0.7031\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7135 - val_loss: 0.5629 - val_accuracy: 0.7135\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7170 - val_loss: 0.5625 - val_accuracy: 0.7083\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7153 - val_loss: 0.5620 - val_accuracy: 0.6979\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7153 - val_loss: 0.5616 - val_accuracy: 0.6979\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7170 - val_loss: 0.5612 - val_accuracy: 0.6979\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7188 - val_loss: 0.5608 - val_accuracy: 0.6979\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7153 - val_loss: 0.5604 - val_accuracy: 0.6979\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7153 - val_loss: 0.5600 - val_accuracy: 0.6979\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7135 - val_loss: 0.5596 - val_accuracy: 0.6979\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7153 - val_loss: 0.5592 - val_accuracy: 0.6979\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7153 - val_loss: 0.5588 - val_accuracy: 0.6979\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7188 - val_loss: 0.5584 - val_accuracy: 0.7031\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7170 - val_loss: 0.5580 - val_accuracy: 0.7031\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7170 - val_loss: 0.5576 - val_accuracy: 0.7031\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7153 - val_loss: 0.5573 - val_accuracy: 0.7135\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7135 - val_loss: 0.5569 - val_accuracy: 0.7188\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5216 - accuracy: 0.7135 - val_loss: 0.5565 - val_accuracy: 0.7240\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5212 - accuracy: 0.7118 - val_loss: 0.5562 - val_accuracy: 0.7240\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5209 - accuracy: 0.7101 - val_loss: 0.5558 - val_accuracy: 0.7240\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7135 - val_loss: 0.5555 - val_accuracy: 0.7240\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7153 - val_loss: 0.5552 - val_accuracy: 0.7240\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7153 - val_loss: 0.5548 - val_accuracy: 0.7240\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7153 - val_loss: 0.5545 - val_accuracy: 0.7240\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7135 - val_loss: 0.5542 - val_accuracy: 0.7240\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7153 - val_loss: 0.5539 - val_accuracy: 0.7240\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7118 - val_loss: 0.5536 - val_accuracy: 0.7240\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7101 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7101 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7118 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7101 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7083 - val_loss: 0.5520 - val_accuracy: 0.7240\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7083 - val_loss: 0.5517 - val_accuracy: 0.7188\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7118 - val_loss: 0.5514 - val_accuracy: 0.7188\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7083 - val_loss: 0.5512 - val_accuracy: 0.7188\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7083 - val_loss: 0.5509 - val_accuracy: 0.7188\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7101 - val_loss: 0.5506 - val_accuracy: 0.7188\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7101 - val_loss: 0.5503 - val_accuracy: 0.7188\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7101 - val_loss: 0.5500 - val_accuracy: 0.7188\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7118 - val_loss: 0.5498 - val_accuracy: 0.7188\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7135 - val_loss: 0.5495 - val_accuracy: 0.7188\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7153 - val_loss: 0.5493 - val_accuracy: 0.7188\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7153 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7153 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7170 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7153 - val_loss: 0.5483 - val_accuracy: 0.7188\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7170 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7188 - val_loss: 0.5478 - val_accuracy: 0.7188\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.7205 - val_loss: 0.5476 - val_accuracy: 0.7188\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7205 - val_loss: 0.5473 - val_accuracy: 0.7188\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7205 - val_loss: 0.5471 - val_accuracy: 0.7188\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7188 - val_loss: 0.5469 - val_accuracy: 0.7188\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5117 - accuracy: 0.7188 - val_loss: 0.5467 - val_accuracy: 0.7188\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7205 - val_loss: 0.5465 - val_accuracy: 0.7188\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7205 - val_loss: 0.5462 - val_accuracy: 0.7188\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7222 - val_loss: 0.5460 - val_accuracy: 0.7188\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7222 - val_loss: 0.5458 - val_accuracy: 0.7188\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7205 - val_loss: 0.5456 - val_accuracy: 0.7188\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7222 - val_loss: 0.5454 - val_accuracy: 0.7188\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7240 - val_loss: 0.5452 - val_accuracy: 0.7240\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7240 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7240 - val_loss: 0.5448 - val_accuracy: 0.7292\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7240 - val_loss: 0.5445 - val_accuracy: 0.7292\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7240 - val_loss: 0.5443 - val_accuracy: 0.7292\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7240 - val_loss: 0.5441 - val_accuracy: 0.7292\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7240 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7240 - val_loss: 0.5437 - val_accuracy: 0.7292\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7257 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7257 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7257 - val_loss: 0.5432 - val_accuracy: 0.7292\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7257 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7257 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7274 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7274 - val_loss: 0.5424 - val_accuracy: 0.7292\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7274 - val_loss: 0.5422 - val_accuracy: 0.7292\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7292 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7309 - val_loss: 0.5418 - val_accuracy: 0.7292\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7326 - val_loss: 0.5416 - val_accuracy: 0.7240\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7344 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7344 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7344 - val_loss: 0.5409 - val_accuracy: 0.7292\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7344 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7344 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7378 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7378 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7378 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7361 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7361 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7361 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7344 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7361 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7378 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7378 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7378 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7378 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7378 - val_loss: 0.5381 - val_accuracy: 0.7344\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7378 - val_loss: 0.5379 - val_accuracy: 0.7344\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7378 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7378 - val_loss: 0.5375 - val_accuracy: 0.7344\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7378 - val_loss: 0.5374 - val_accuracy: 0.7344\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7396 - val_loss: 0.5372 - val_accuracy: 0.7344\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7396 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7396 - val_loss: 0.5369 - val_accuracy: 0.7344\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7396 - val_loss: 0.5367 - val_accuracy: 0.7344\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7396 - val_loss: 0.5366 - val_accuracy: 0.7344\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7413 - val_loss: 0.5364 - val_accuracy: 0.7344\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5008 - accuracy: 0.7413 - val_loss: 0.5362 - val_accuracy: 0.7344\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.7413 - val_loss: 0.5361 - val_accuracy: 0.7344\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7396 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.7413 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7396 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7413 - val_loss: 0.5355 - val_accuracy: 0.7396\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7413 - val_loss: 0.5353 - val_accuracy: 0.7396\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7431 - val_loss: 0.5352 - val_accuracy: 0.7396\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4994 - accuracy: 0.7431 - val_loss: 0.5350 - val_accuracy: 0.7396\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7448 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7431 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7431 - val_loss: 0.5346 - val_accuracy: 0.7396\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7448 - val_loss: 0.5345 - val_accuracy: 0.7396\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7448 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7448 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7448 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7448 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7448 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7448 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7465 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7448 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7465 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7465 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7448 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7465 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7465 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7465 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7465 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7465 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7483 - val_loss: 0.5322 - val_accuracy: 0.7500\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7483 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7483 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7465 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7465 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7483 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7483 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7483 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7483 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7483 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7500 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7483 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7483 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7500 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7500 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7500 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7500 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7500 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7500 - val_loss: 0.5300 - val_accuracy: 0.7552\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7500 - val_loss: 0.5299 - val_accuracy: 0.7552\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7500 - val_loss: 0.5298 - val_accuracy: 0.7552\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7500 - val_loss: 0.5297 - val_accuracy: 0.7552\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7517 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7535 - val_loss: 0.5295 - val_accuracy: 0.7552\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7552 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7552 - val_loss: 0.5293 - val_accuracy: 0.7604\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7535 - val_loss: 0.5292 - val_accuracy: 0.7604\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7535 - val_loss: 0.5290 - val_accuracy: 0.7604\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7535 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7552 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7552 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7552 - val_loss: 0.5286 - val_accuracy: 0.7604\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7569 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7569 - val_loss: 0.5284 - val_accuracy: 0.7604\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7569 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7569 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7587 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7587 - val_loss: 0.5280 - val_accuracy: 0.7604\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7587 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7604 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7587 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.7587 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.65 - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7604 - val_loss: 0.5275 - val_accuracy: 0.7552\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7604 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7587 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7622 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7622 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7639 - val_loss: 0.5270 - val_accuracy: 0.7500\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7639 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4896 - accuracy: 0.7639 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7639 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7639 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7639 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7656 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7656 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7674 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7674 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7656 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7656 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7656 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7656 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7674 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7674 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7674 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7674 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7691 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7691 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7691 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7708 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7708 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7708 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7708 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7708 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7708 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7708 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7691 - val_loss: 0.5245 - val_accuracy: 0.7552\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7674 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7674 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7674 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7674 - val_loss: 0.5240 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7656 - val_loss: 0.5238 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7656 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7656 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7674 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7674 - val_loss: 0.5235 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7674 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7674 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7674 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7674 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7656 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7656 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7656 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7656 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7656 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7656 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7674 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7674 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7674 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7674 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7674 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7674 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7674 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7691 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7691 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7691 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7691 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7691 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7691 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7691 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7691 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7691 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.5211 - val_accuracy: 0.7552\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7708 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7708 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7708 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7708 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7708 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7726 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7726 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7726 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7726 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7726 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7726 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7708 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7708 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7674 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7691 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7708 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7674 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7656 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7656 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7674 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7674 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7674 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7674 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7674 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7674 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.7674 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7674 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7674 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7674 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7674 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7674 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7656 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7674 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7656 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7656 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7656 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7656 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7656 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7656 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7656 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7674 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7674 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7674 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7674 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7674 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7691 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7691 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7691 - val_loss: 0.5159 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.5159 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7691 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7708 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7708 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7708 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7708 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7708 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7708 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7708 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7708 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7708 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7708 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7708 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.84 - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7743 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7847 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7865 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7865 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7865 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7865 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4535 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7882 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8021 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8021 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8021 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8021 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.78 - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4250 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8073 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8056 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8073 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8056 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8056 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8056 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8056 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8056 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8056 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8056 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8056 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8056 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8056 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8056 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8056 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8073 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.8073 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8073 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8073 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8073 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8073 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8073 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8073 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8073 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.8073 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8073 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8073 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8090 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8090 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8073 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8073 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8073 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8073 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8090 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8073 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8073 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8073 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8090 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8090 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8073 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8073 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8073 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8073 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8090 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8090 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8073 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8108 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8090 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8108 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8090 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8090 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8108 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8108 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8108 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8090 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8108 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8090 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8090 - val_loss: 0.5152 - val_accuracy: 0.7552\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8090 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8108 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8090 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8108 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8108 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8090 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8108 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8108 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8108 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8108 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8108 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8108 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8108 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8108 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8108 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8108 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8108 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8108 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.5159 - val_accuracy: 0.7552\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8108 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8108 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5165 - val_accuracy: 0.7552\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5166 - val_accuracy: 0.7552\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8108 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8108 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8108 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8125 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8108 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8125 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8125 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8125 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8125 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8125 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8125 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8125 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8125 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8125 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8142 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8142 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8142 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8125 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8142 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8142 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8142 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8142 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8142 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8142 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8142 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8142 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8142 - val_loss: 0.5184 - val_accuracy: 0.7604\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8142 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8142 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8142 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8142 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8142 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8142 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8142 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8142 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8125 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8142 - val_loss: 0.5187 - val_accuracy: 0.7604\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8142 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8125 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8142 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8125 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8142 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8125 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8125 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8142 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8125 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8125 - val_loss: 0.5190 - val_accuracy: 0.7604\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8125 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8125 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8125 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8125 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8142 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4184 - accuracy: 0.8125 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.8125 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8142 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8125 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8125 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8125 - val_loss: 0.5193 - val_accuracy: 0.7604\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8142 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8125 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8125 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8142 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8125 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8142 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8142 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8125 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8142 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8142 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8125 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8142 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8142 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8142 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8142 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8142 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8142 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8125 - val_loss: 0.5200 - val_accuracy: 0.7604\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8142 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5202 - val_accuracy: 0.7604\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8142 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8142 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8142 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8142 - val_loss: 0.5204 - val_accuracy: 0.7604\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8142 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8142 - val_loss: 0.5205 - val_accuracy: 0.7604\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8142 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8142 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8142 - val_loss: 0.5206 - val_accuracy: 0.7604\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8142 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8142 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8142 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8142 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8142 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8142 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8142 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8142 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8142 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8142 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8125 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8142 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8142 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8142 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8142 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8125 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8125 - val_loss: 0.5216 - val_accuracy: 0.7604\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8125 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4163 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8125 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8125 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8125 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8125 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8125 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8125 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8125 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8125 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8142 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8142 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8142 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8142 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8142 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8142 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8142 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8142 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8142 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8142 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8142 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8142 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8142 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8142 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8142 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8142 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8142 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8142 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8142 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8142 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8142 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8142 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8142 - val_loss: 0.5248 - val_accuracy: 0.7656\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8142 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8142 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8142 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8142 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8142 - val_loss: 0.5254 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.641\n",
      "roc-auc is 0.818\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_x = model_2.predict(X_test_norm)\n",
    "y_pred_class_nn_2 = np.argmax(predict_x,axis=1)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66aefaa15347530fd336e5ff4c6baa78eb01ac4bdb41d42482c99492d43d4e3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
